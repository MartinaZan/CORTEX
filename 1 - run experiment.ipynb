{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from src.evaluation.evaluator_manager import EvaluatorManager\n",
    "from src.evaluation.evaluator_manager_do import EvaluatorManager as PairedEvaluatorManager\n",
    "from src.evaluation.evaluator_manager_triplets import EvaluatorManager as TripletsEvaluatorManager\n",
    "\n",
    "from src.utils.context import Context\n",
    "\n",
    "from utils_martina.my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set patient and record (same channels)\n",
    "\n",
    "# observations = [\"chb01_03\", \"chb01_04\", \"chb01_15\", \"chb01_16\", \"chb01_18\", \"chb01_21\", \"chb01_26\"]\n",
    "# observations = [\"chb03_01\", \"chb03_02\", \"chb03_03\", \"chb03_04\", \"chb03_34\", \"chb03_35\", \"chb03_36\"]\n",
    "\n",
    "# observations = [\"chb02_16\", \"chb02_19\"]\n",
    "\n",
    "observations = [\"chb04_28\"]\n",
    "# observations = [\"chb05_06\", \"chb05_13\", \"chb05_16\", \"chb05_17\", \"chb05_22\"]\n",
    "# observations = [\"chb06_01\", \"chb06_04\"] #, \"chb06_09\", \"chb06_10\", \"chb06_13\", \"chb06_18\", \"chb06_24\"]\n",
    "\n",
    "# observations = [\"PN00_1\", \"PN00_2\", \"PN00_4\", \"PN00_5\"]\n",
    "# observations = [\"PN14_1\", \"PN14_2\", \"PN14_3\", \"PN14_4\"]\n",
    "\n",
    "# observations = [\"PN14_4\"]\n",
    "# observations = [\"chb01_16\"]\n",
    "\n",
    "create_dataset_json(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = \"..\\\\..\\\\explainability\\GRETEL-repo\\\\output\\\\logs\\\\\"\n",
    "eval_manager_path = \"..\\\\..\\\\explainability\\GRETEL-repo\\\\output\\\\eval_manager\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing cache data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed file: .\\data\\cache\\datasets\\GCS-28e49373646e3a1aa4f78d3b3cf52c7d\n",
      "Removed folder: .\\data\\cache\\oracles\\GCS-28e49373646e3a1aa4f78d3b3cf52c7d\n"
     ]
    }
   ],
   "source": [
    "remove_cache = True\n",
    "\n",
    "if remove_cache:\n",
    "    list_folders = [\".\\data\\cache\\datasets\", \".\\data\\cache\\explainers\", \".\\data\\cache\\oracles\"]\n",
    "\n",
    "    for folder in list_folders:\n",
    "        for file in os.listdir(folder):\n",
    "            if file.startswith(\"GCS-\"):  # Checks if the file begins with \"GCS-\"\n",
    "                cache_path = os.path.join(folder, file)\n",
    "                if os.path.isfile(cache_path):\n",
    "                    os.remove(cache_path)\n",
    "                    print(f\"Removed file: {cache_path}\")\n",
    "                elif os.path.isdir(cache_path):\n",
    "                    shutil.rmtree(cache_path)\n",
    "                    print(f\"Removed folder: {cache_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Gretel experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE: If it crashes, check if there are any OracleTorch files from the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'config/GCS-GCN.jsonc'\n",
    "# path = 'config/GCS-SVM.jsonc'\n",
    "# path = 'config/GCS-KNN.jsonc'\n",
    "\n",
    "print(observations)\n",
    "\n",
    "print(f\"Generating context for: {path}\")\n",
    "context = Context.get_context(path)\n",
    "context.run_number = -1\n",
    "\n",
    "context.logger.info(f\"Executing: {context.config_file} Run: {context.run_number}\")\n",
    "context.logger.info(\n",
    "    \"Creating the evaluation manager.......................................................\"\n",
    ")\n",
    "\n",
    "if 'doe-triplets' in context.conf:\n",
    "    context.logger.info(\"Creating the TRIPLET evaluators........................................................\")\n",
    "    eval_manager = TripletsEvaluatorManager(context)\n",
    "if 'do-pairs' in context.conf:\n",
    "    context.logger.info(\"Creating the PAIRED evaluators...............................................................\") ### Usiamo questo\n",
    "    eval_manager = PairedEvaluatorManager(context)\n",
    "else:\n",
    "    context.logger.info(\"Creating the evaluators...............................................................\")\n",
    "    eval_manager = EvaluatorManager(context)\n",
    "\n",
    "context.logger.info(\n",
    "    \"Evaluating the explainers.............................................................\"\n",
    ")\n",
    "\n",
    "eval_manager.evaluate()\n",
    "\n",
    "# Additional stuff\n",
    "print('--------------------------------------')\n",
    "\n",
    "for i in range(len(eval_manager._evaluators)):\n",
    "    # context.logger.info(f\"graph_ids: {eval_manager._evaluators[i].get_instance_and_counterfactual_ids()}\") # NON Ãˆ STATO SISTEMATO PER CONTEMPLARE IL CASO DI PIU' PAZIENTI\n",
    "    context.logger.info(f\"graph_metrics: {eval_manager._evaluators[i].get_instance_and_counterfactual_graph_metrics()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save eval_manager to file\n",
    "file_name = get_most_recent_file(logs_path).split('.')[0]\n",
    "\n",
    "with open(eval_manager_path + file_name + \".pkl\", 'wb') as f:\n",
    "    pickle.dump(eval_manager, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _______________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last full run: 30/04/2025, ore 10:42\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(\"Last full run:\", now.strftime(\"%d/%m/%Y, ore %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "winsound.Beep(440, 500)\n",
    "winsound.Beep(400, 500)\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data_analysis.future.data_analyzer import DataAnalyzer as data_analyzer\n",
    "\n",
    "# results_path = \"output\\\\results\"\n",
    "# stats_file_path = \"output\"\n",
    "# res = data_analyzer.create_aggregated_dataframe(results_path)\n",
    "# res.to_csv(stats_file_path)\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRETEL_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
