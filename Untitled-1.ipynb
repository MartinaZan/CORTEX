{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95d0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa26924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from utils_martina.my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a5b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = \"..\\\\..\\\\explainability\\GRETEL-repo\\\\output\\\\logs\\\\\"\n",
    "eval_manager_path = \"..\\\\..\\\\explainability\\GRETEL-repo\\\\output\\\\eval_manager\\\\\"\n",
    "output_path = \"..\\\\..\\\\explainability\\GRETEL-repo\\\\output\\\\evolution_3d_embeddings\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407572e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31352-Martina\n"
     ]
    }
   ],
   "source": [
    "file_name = get_most_recent_file(eval_manager_path).split('.')[0]\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72650c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set patient and record\n",
    "\n",
    "# [\"chb01_03\", \"chb01_04\", \"chb01_15\", \"chb01_16\", \"chb01_18\", \"chb01_21\", \"chb01_26\"]\n",
    "patient_id = \"chb01\"\n",
    "record_id = \"21\"\n",
    "\n",
    "# No penalizzazione temporale\n",
    "# file_name = 16688-Martina\n",
    "\n",
    "# Penalizzazione temporale\n",
    "# file_name = 26040-Martina\n",
    "\n",
    "if patient_id[:2] == \"PN\":      # Frequency Siena dataset\n",
    "    frequency = 512\n",
    "elif patient_id[:3] == \"chb\":   # Frequency CHB-MIT dataset\n",
    "    frequency = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509efd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information related to the EEG of patient_id, record_id\n",
    "with open(f\"EEG_data\\EEG_data_params_{patient_id}_{record_id}.pkl\", \"rb\") as f:\n",
    "    loaded_variables = pickle.load(f)\n",
    "\n",
    "indices = loaded_variables[\"indici\"]\n",
    "Start = loaded_variables[\"Start\"]\n",
    "End = loaded_variables[\"End\"]\n",
    "seizure_starts = loaded_variables[\"seizure_starts\"]\n",
    "seizure_ends = loaded_variables[\"seizure_ends\"]\n",
    "seizure_class = loaded_variables[\"seizure_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a68289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logs\n",
    "with open(logs_path + file_name + '.info', \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Load eval_manager\n",
    "with open(eval_manager_path + file_name + '.pkl', 'rb') as f:\n",
    "    eval_manager = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51b28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_instance_list = []\n",
    "\n",
    "pairs = eval_manager._evaluators[0].get_instance_explanation_pairs()\n",
    "for g1 in eval_manager._evaluators[0].dataset.instances:\n",
    "    graph_instance_list.append(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e469bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "\n",
    "# --- Supponiamo che graph_instance_list sia la lista dei tuoi GraphInstance\n",
    "\n",
    "def graph_instance_to_pyg_data(graph_instance):\n",
    "    edge_index = torch.tensor(np.vstack(np.nonzero(graph_instance.data)), dtype=torch.long)\n",
    "    x = torch.tensor(graph_instance.node_features, dtype=torch.float)\n",
    "    edge_attr = None\n",
    "    if graph_instance.edge_features is not None:\n",
    "        edge_attr = torch.tensor(graph_instance.edge_features, dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "pyg_data_list = [graph_instance_to_pyg_data(g) for g in graph_instance_list]\n",
    "\n",
    "loader = DataLoader(pyg_data_list, batch_size=16, shuffle=True)\n",
    "\n",
    "# --- Parametri (modifica in base al tuo dataset)\n",
    "node_feat_dim = pyg_data_list[0].x.shape[1]\n",
    "latent_dim = 32\n",
    "hidden_dim = 64\n",
    "num_nodes = pyg_data_list[0].x.shape[0]  # se variabile, serve gestione piÃ¹ avanzata\n",
    "\n",
    "class GraphEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x\n",
    "\n",
    "class GraphDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, num_nodes):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(latent_dim, num_nodes * num_nodes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        adj_recon = self.linear(z)\n",
    "        adj_recon = adj_recon.view(-1, num_nodes, num_nodes)\n",
    "        adj_recon = torch.sigmoid(adj_recon)\n",
    "        return adj_recon\n",
    "\n",
    "class GraphAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim, num_nodes):\n",
    "        super().__init__()\n",
    "        self.encoder = GraphEncoder(in_channels, hidden_channels, latent_dim)\n",
    "        self.decoder = GraphDecoder(latent_dim, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encoder(data.x, data.edge_index, data.batch)\n",
    "        adj_recon = self.decoder(z)\n",
    "        return adj_recon\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphAutoencoder(node_feat_dim, hidden_dim, latent_dim, num_nodes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1676ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3782\n",
      "Epoch 2, Loss: 0.3744\n",
      "Epoch 3, Loss: 0.3736\n",
      "Epoch 4, Loss: 0.3735\n",
      "Epoch 5, Loss: 0.3728\n",
      "Epoch 6, Loss: 0.3727\n",
      "Epoch 7, Loss: 0.3724\n",
      "Epoch 8, Loss: 0.3730\n",
      "Epoch 9, Loss: 0.3725\n",
      "Epoch 10, Loss: 0.3727\n",
      "Epoch 11, Loss: 0.3731\n",
      "Epoch 12, Loss: 0.3735\n",
      "Epoch 13, Loss: 0.3727\n",
      "Epoch 14, Loss: 0.3727\n",
      "Epoch 15, Loss: 0.3730\n",
      "Epoch 16, Loss: 0.3731\n",
      "Epoch 17, Loss: 0.3727\n",
      "Epoch 18, Loss: 0.3732\n",
      "Epoch 19, Loss: 0.3731\n",
      "Epoch 20, Loss: 0.3729\n",
      "Epoch 21, Loss: 0.3728\n",
      "Epoch 22, Loss: 0.3729\n",
      "Epoch 23, Loss: 0.3727\n",
      "Epoch 24, Loss: 0.3727\n",
      "Epoch 25, Loss: 0.3730\n",
      "Epoch 26, Loss: 0.3730\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m node_indices \u001b[38;5;241m=\u001b[39m node_mask\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Trova archi per cui entrambi i nodi sono in node_indices\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_indices\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m edges \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39medge_index[:, edge_mask]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Mappa gli indici dei nodi da globali a locali per il grafo i\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# node_indices contiene i nodi globali, dobbiamo riscrivere edges con indici locali (0..num_nodes_i-1)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        adj_recon = model(batch)  # (batch_size, num_nodes, num_nodes)\n",
    "\n",
    "        # Costruiamo matrice di adiacenza target batch-wise\n",
    "        # batch.edge_index ha archi concatenati, dobbiamo fare matrice per ogni grafo\n",
    "        # Qui semplifico supponendo num_nodes fisso e batch con grafi indipendenti\n",
    "        \n",
    "        batch_size = adj_recon.size(0)\n",
    "        adj_true = torch.zeros((batch_size, num_nodes, num_nodes), device=device)\n",
    "        \n",
    "        node_offset = 0\n",
    "        for i in range(batch_size):\n",
    "            # Nodi appartenenti al grafo i\n",
    "            node_mask = (batch.batch == i)\n",
    "            node_indices = node_mask.nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "            # Trova archi per cui entrambi i nodi sono in node_indices\n",
    "            edge_mask = (torch.isin(batch.edge_index[0], node_indices) & torch.isin(batch.edge_index[1], node_indices))\n",
    "\n",
    "            edges = batch.edge_index[:, edge_mask]\n",
    "\n",
    "            # Mappa gli indici dei nodi da globali a locali per il grafo i\n",
    "            # node_indices contiene i nodi globali, dobbiamo riscrivere edges con indici locali (0..num_nodes_i-1)\n",
    "            node_id_map = {node.item(): idx for idx, node in enumerate(node_indices)}\n",
    "\n",
    "            edges_local = torch.zeros_like(edges)\n",
    "            edges_local[0] = torch.tensor([node_id_map[n.item()] for n in edges[0]])\n",
    "            edges_local[1] = torch.tensor([node_id_map[n.item()] for n in edges[1]])                                                                                                                                                                                                                    \n",
    "\n",
    "            adj_true[i, edges_local[0], edges_local[1]] = 1.0\n",
    "        \n",
    "        loss = F.binary_cross_entropy(adj_recon, adj_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRETEL_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
